{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From model training to deployment - an introduction to the SmartPredictor object\n",
    "\n",
    "Shapash create a SmartPredictor to make prediction and have explainability for operational needs in deployment context. <br />\n",
    "Explainability can be restitutate to users to have a simple synthetic explanation. <br />\n",
    "SmartPredictor allows users to configure the summary to satisfy their operational needs. <br />\n",
    "It is an object dedicated to deployment, lighter and more consistent than Smartexplainer. <br />\n",
    "SmartPredictor can be used with an API or in batch mode. <br />\n",
    "\n",
    "In this tutorial, we will go further to help you getting started with the SmartPredictor Object of Shapash.\n",
    "\n",
    "Contents:\n",
    "- Build a SmartPredictor\n",
    "- Save and Load a Smartpredictor\n",
    "- Add input\n",
    "- Use label and wording\n",
    "- Summarize explaination\n",
    "\n",
    "We used Kaggle's [Titanic](https://www.kaggle.com/c/titanic) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import a dataset. Here we chose the famous dataset Titanic from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "from shapash.explainer.smart_predictor import SmartPredictor\n",
    "from shapash.utils.load_smartpredictor import load_smartpredictor\n",
    "from shapash.data.data_loader import data_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titan_df, titan_dict = data_loading('titanic')\n",
    "del titan_df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. table:: \n",
      "\n",
      "    +--------+-----------+------+---+-----+-----+-----+-----------+-----+\n",
      "    |Survived|  Pclass   | Sex  |Age|SibSp|Parch|Fare | Embarked  |Title|\n",
      "    +========+===========+======+===+=====+=====+=====+===========+=====+\n",
      "    |       0|Third class|male  | 22|    1|    0| 7.25|Southampton|Mr   |\n",
      "    +--------+-----------+------+---+-----+-----+-----+-----------+-----+\n",
      "    |       1|First class|female| 38|    1|    0|71.28|Cherbourg  |Mrs  |\n",
      "    +--------+-----------+------+---+-----+-----+-----+-----------+-----+\n",
      "    |       1|Third class|female| 26|    0|    0| 7.92|Southampton|Miss |\n",
      "    +--------+-----------+------+---+-----+-----+-----+-----------+-----+\n",
      "    |       1|First class|female| 35|    1|    0|53.10|Southampton|Mrs  |\n",
      "    +--------+-----------+------+---+-----+-----+-----+-----------+-----+\n",
      "    |       0|Third class|male  | 35|    0|    0| 8.05|Southampton|Mr   |\n",
      "    +--------+-----------+------+---+-----+-----+-----+-----------+-----+\n"
     ]
    }
   ],
   "source": [
    "titan_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train a Machine Learning supervized model with our data. In our example, we are confronted to a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = titan_df['Survived']\n",
    "X = titan_df.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "varcat=['Pclass','Sex','Embarked','Title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use a preprocessing on our data for handling categorical features before the training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_encoding = OrdinalEncoder(cols=varcat, \\\n",
    "                                handle_unknown='ignore', \\\n",
    "                                return_df=True).fit(X)\n",
    "X = categ_encoding.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test split + Random Forest fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.75, random_state=1)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,min_samples_leaf=3)\n",
    "rf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=pd.DataFrame(rf.predict(Xtest),columns=['pred'],index=Xtest.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Smarpredictor from you SmartExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the training step is done, we can start to initialize our SmartExplainer Object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash.explainer.smart_explainer import SmartExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SmartExplainer takes only necessary dicts of the model features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Label and Wording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use labels and wording to get a more understandable explanabily.\n",
    "- features_dict : allow users to rename the features of their datasets with the one needed\n",
    "- label_dict : allow users in classification problems to rename label predicted with the one needed\n",
    "- postprocessing : allow users to apply some wording to the features wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {'Pclass': 'Ticket class',\n",
    " 'Sex': 'Sex',\n",
    " 'Age': 'Age',\n",
    " 'SibSp': 'Relatives such as brother or wife',\n",
    " 'Parch': 'Relatives like children or parents',\n",
    " 'Fare': 'Passenger fare',\n",
    " 'Embarked': 'Port of embarkation',\n",
    " 'Title': 'Title of passenger'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {0: \"Not Survived\",1: \"Survived\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing = {\"Pclass\": {'type': 'transcoding', 'rule': { 'First class' : '1st class', 'Second class' : '2nd class', \"Third class\" : \"3rd class\"}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpl = SmartExplainer(label_dict = label_dict, features_dict=feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend: Shap TreeExplainer\n"
     ]
    }
   ],
   "source": [
    "xpl.compile(\n",
    "    x=Xtest,\n",
    "    model=rf,\n",
    "    preprocessing=categ_encoding,\n",
    "    y_pred=ypred,\n",
    "    postprocessing = postprocessing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch to SmartPredictor Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to_smartpredictor() is a method create to get a SmartPredictor object.\n",
    "- It allows users to switch from a SmartExplainer used for data mining to the SmartPredictor.\n",
    "- SmartPredictor takes only neccessary attribute to be lighter and more consistent than Smartexplainer.\n",
    "- SmartPredictor object is specific for deployement. \n",
    "- In this section, we will learn how to initialize a SmartPredictor.\n",
    "- SmartPredictor allows you not to only understand results of your models but also to produce those results on new data automatically.\n",
    "- It will make new predictions and summarize explainability that you configured  to make it operational to your needs.\n",
    "- SmartPredictor take only neccessary attribute to be lighter and more consistent than Smartexplainer for deployment context. \n",
    "- SmartPredictor can be use with API or in batch mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = xpl.to_smartpredictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your predictor in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.save('./predictor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load your predictor in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_load = load_smartpredictor('./predictor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction with your SmartPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once our SmartPredictor has been initialized, we can easily apply predictions and summary to new datasets.\n",
    "- First, we have to specify a new dataset which can be a pandas.DataFrame or a dictionnary (usefull when you decide to use an API in your deployment process)\n",
    "- We will use the add_input method of the SmartPredictor. (see the documentation for this method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_x = {'Pclass': 'First class',\n",
    " 'Sex': 'female',\n",
    " 'Age': 36,\n",
    " 'SibSp': 1,\n",
    " 'Parch': 0,\n",
    " 'Fare': 7.25,\n",
    " 'Embarked': 'Cherbourg',\n",
    " 'Title': 'Miss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_load.add_input(x=person_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't specify an ypred in the add_input method, SmartPredictor will use its predict method to automatically affect the predicted value to ypred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can see that ypred is automatically computed in add_input method by checking the attribute data[\"ypred\"] thanks to our model trained and the new dataset given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. table:: \n",
      "\n",
      "    +--------+------+\n",
      "    | ypred  |proba |\n",
      "    +========+======+\n",
      "    |Survived|0.7156|\n",
      "    +--------+------+\n"
     ]
    }
   ],
   "source": [
    "predictor_load.data[\"ypred\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the predict_proba method of the SmartPredictor to automatically compute the probabilties associated to each label possible with our model and the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_proba = predictor_load.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. table:: \n",
      "\n",
      "    +-------+-------+\n",
      "    |class_0|class_1|\n",
      "    +=======+=======+\n",
      "    | 0.2376| 0.7624|\n",
      "    +-------+-------+\n"
     ]
    }
   ],
   "source": [
    "prediction_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get detailed explanability associated to the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use the method detail_contributions to see the detailed contributions of each of your features for each row of your new dataset.\n",
    "- For classification problems, it will automatically associated contributions with the right predicted label. (like you can see below) \n",
    "- The predicted label can be compute automatically with predict method or you can specify in add_input method an ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_contributions = predictor_load.detail_contributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice here that the ypred has already been renamed with the value that we have given in the label_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. table:: \n",
      "\n",
      "    +--------+------+------+------+--------+--------+---------+--------+--------+------+\n",
      "    | ypred  |proba |Pclass| Sex  |  Age   | SibSp  |  Parch  |  Fare  |Embarked|Title |\n",
      "    +========+======+======+======+========+========+=========+========+========+======+\n",
      "    |Survived|0.7624|0.1097|0.1586|-0.02100|0.007639|-0.003601|-0.09370| 0.04038|0.1928|\n",
      "    +--------+------+------+------+--------+--------+---------+--------+--------+------+\n"
     ]
    }
   ],
   "source": [
    "detailed_contributions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize explanability of the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use the summarize method to summarize your local explainability\n",
    "- This summary can be configured with the method modify_mask in order for you to have the explainability that satisfy your operational needs\n",
    "- You can also specify :\n",
    ">- a postprocessing when you initialize your SmartPredictor to apply a wording to several values of your dataset.\n",
    ">- a label_dict to rename your label in classification problems (during the initialisation of your SmartPredictor).\n",
    ">- a features_dict to rename your features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we chose to use modify_mask method to only get the 3 most contributives features in our explanability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_load.modify_mask(max_contrib=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = predictor_load.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can notice in the summarize that the dictionnary of mapping given to the SmartExplainer Object allow us to rename the 'Title' feature into 'Title of passenger'. \n",
    "- Also, we can see that the value of this features has been worded correctly has we configured it : First class became 1st class.\n",
    "- Our explanability is focused on the 3 most contributive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. table:: \n",
      "\n",
      "    +--------+------+------------------+-------+--------------+---------+-------+--------------+------------+---------+--------------+\n",
      "    | ypred  |proba |    feature_1     |value_1|contribution_1|feature_2|value_2|contribution_2| feature_3  | value_3 |contribution_3|\n",
      "    +========+======+==================+=======+==============+=========+=======+==============+============+=========+==============+\n",
      "    |Survived|0.7624|Title of passenger|Miss   |        0.1928|Sex      |female |        0.1586|Ticket class|1st class|        0.1097|\n",
      "    +--------+------+------------------+-------+--------------+---------+-------+--------------+------------+---------+--------------+\n"
     ]
    }
   ],
   "source": [
    "explanation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your summary easily\n",
    "\n",
    "#### If contributions wanted are the ones associated to the class 0 (More useful in multiclass classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can easily change the ypred or the x given to the add_input to make new prediction and summary of your explanability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify an ypred to get explanability from the label that you prefer to predict instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_load.add_input(x=person_x, ypred=pd.DataFrame({0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_load.modify_mask(max_contrib=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = predictor_load.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we changed the ypred from label predicted 1 to 0 which allow us to automatically get the explanability of features that are associated to the right label predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. table:: \n",
      "\n",
      "    +------------+------+------------------+-------+--------------+---------+-------+--------------+------------+---------+--------------+\n",
      "    |     0      |proba |    feature_1     |value_1|contribution_1|feature_2|value_2|contribution_2| feature_3  | value_3 |contribution_3|\n",
      "    +============+======+==================+=======+==============+=========+=======+==============+============+=========+==============+\n",
      "    |Not Survived|0.2376|Title of passenger|Miss   |       -0.1928|Sex      |female |       -0.1586|Ticket class|1st class|       -0.1097|\n",
      "    +------------+------+------------------+-------+--------------+---------+-------+--------------+------------+---------+--------------+\n"
     ]
    }
   ],
   "source": [
    "explanation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If users don't want one feature and want only positive contributions to restituate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The modify_mask method allows us to configure the explanability to satisfy our needs in opeartional process.\n",
    "- Here, we can choose to hide some features from our explanability and only get the one which has positive contributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_load.modify_mask(features_to_hide=[\"Sex\"], positive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = predictor_load.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. table:: \n",
      "\n",
      "    +------------+------+--------------+-------+--------------+---------+-------+--------------+----------------------------------+-------+--------------+\n",
      "    |     0      |proba |  feature_1   |value_1|contribution_1|feature_2|value_2|contribution_2|            feature_3             |value_3|contribution_3|\n",
      "    +============+======+==============+=======+==============+=========+=======+==============+==================================+=======+==============+\n",
      "    |Not Survived|0.2376|Passenger fare|   7.25|       0.09370|Age      |     36|       0.02100|Relatives like children or parents|      0|      0.003601|\n",
      "    +------------+------+--------------+-------+--------------+---------+-------+--------------+----------------------------------+-------+--------------+\n"
     ]
    }
   ],
   "source": [
    "explanation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If users want to restituate only contributions with a minimum of impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we chose to only show the features which has a contribution greater than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_load.modify_mask(threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = predictor_load.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. table:: \n",
      "\n",
      "    +------------+------+--------------+-------+--------------+\n",
      "    |     0      |proba |  feature_1   |value_1|contribution_1|\n",
      "    +============+======+==============+=======+==============+\n",
      "    |Not Survived|0.2376|Passenger fare|   7.25|       0.09370|\n",
      "    +------------+------+--------------+-------+--------------+\n"
     ]
    }
   ],
   "source": [
    "explanation.head()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "env_test_shapash_lot2",
   "language": "python",
   "name": "env_test_shapash_lot2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
